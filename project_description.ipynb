{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Image Stitcher\n",
    "## Assigned: 02.01.2019\n",
    "## Due Date: TBD (probably 02.20.2019)\n",
    "\n",
    "Panoramic photography is ubiquitous, with nearly every digital camera having a mode dedicated to doing it.  Here's an example from the Italian Alps:\n",
    "<img src=\"pano.jpg\">\n",
    "Note the extreme aspect ratio: much larger than the 4:3 or 3:2 that is typical of most cameras; suffice to say, the camera that stook this picture did not have a sensor that was this wide.  So how are these things made?  Stated simply, multiple images are taken, mutually identifiable points are located in each of these images, and the images are warped such that these points are coincident.  The matching stage might look like this:\n",
    "<img src=\"office.jpeg\">\n",
    "\n",
    "For this project, you will code your own image stitcher from scratch.  Despite the conceptual simplicity of this operation, there are a surprising number of challenges that need to be addressed.  A general framework for a stitcher might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harris_response import *\n",
    "import skimage.transform as skt\n",
    "\n",
    "\n",
    "class Stitcher(object):\n",
    "\n",
    "    def __init__(self, image_1, image_2):\n",
    "\n",
    "        # Convert both images to gray scale\n",
    "        image_1 = np.mean(image_1, -1)\n",
    "        image_2 = np.mean(image_2, -1)\n",
    "\n",
    "        self.images = [image_1, image_2]\n",
    "\n",
    "    def find_keypoints(self, image, n_keypoints):\n",
    "\n",
    "        \"\"\"\n",
    "        Step 1: This method locates features that are \"good\" for matching.  To do this we will implement the Harris\n",
    "        corner detector\n",
    "        \"\"\"\n",
    "\n",
    "        filter_size = 5\n",
    "\n",
    "        # Setup gauss filter\n",
    "        gauss_filter = Filter.make_gauss((filter_size, filter_size), 2)\n",
    "\n",
    "        # Compute smoothed harris response\n",
    "        out = convolve(compute_harris_response(image, gauss_filter), gauss_filter)  # Smooth results\n",
    "\n",
    "        # Find some good features to match\n",
    "        x, y = adaptive_non_maximal_suppression(out, n_keypoints, filter_size)\n",
    "\n",
    "        # Return the locations\n",
    "        return x, y\n",
    "\n",
    "    def generate_descriptors(self, img, l=21):\n",
    "        \"\"\"\n",
    "        Step 2: After identifying relevant keypoints, we need to come up with a quantitative description of the\n",
    "        neighborhood of that keypoint, so that we can match it to keypoints in other images.\n",
    "        \"\"\"\n",
    "        v, u = self.find_keypoints(img, 100)\n",
    "\n",
    "        ofs = l // 2\n",
    "\n",
    "        d_out = []\n",
    "        u_out = []\n",
    "        v_out = []\n",
    "\n",
    "        m = len(img)\n",
    "        n = len(img[0])\n",
    "\n",
    "        # check for u and v to be same dimensions\n",
    "        for i in range(len(u)):\n",
    "\n",
    "            c_x = v[i]\n",
    "            c_y = u[i]\n",
    "\n",
    "            # If we cannot get a description for key point, throw it out\n",
    "            if c_x + ofs > m or c_x - ofs < 0 or c_y + ofs > n or c_y - ofs < 0:\n",
    "                continue\n",
    "\n",
    "            sub = img[v[i] - ofs: v[i] + ofs + 1, u[i] - ofs: u[i] + ofs + 1]\n",
    "            if sub.shape[0] == l and sub.shape[1] == l:\n",
    "                u_out.append(u[i])\n",
    "                v_out.append(v[i])\n",
    "                d_out.append(sub)\n",
    "\n",
    "        return np.stack(d_out), np.asarray(u_out, dtype=int), np.asarray(v_out, dtype=int)\n",
    "\n",
    "    def D_hat(self, d):\n",
    "        return (d - d.mean()) / np.std(d)\n",
    "\n",
    "    def error(self, d1, d2):\n",
    "        return np.sum((d1 - d2) ** 2)\n",
    "\n",
    "    def match_keypoints(self, r=0.7):\n",
    "        \"\"\"\n",
    "        Step 3: Compare keypoint descriptions between images, identify potential matches, and filter likely\n",
    "        mismatches\n",
    "        \"\"\"\n",
    "\n",
    "        d1, u1, v1 = self.generate_descriptors(img=self.images[0])\n",
    "        d2, u2, v2 = self.generate_descriptors(img=self.images[1])\n",
    "\n",
    "        kp1 = []\n",
    "        kp2 = []\n",
    "\n",
    "        for i in range(len(d1)):\n",
    "            d1_hat = self.D_hat(d1[i])\n",
    "            er_best = np.inf\n",
    "            er_second = np.inf\n",
    "\n",
    "            for j in range(len(d2)):\n",
    "                d2_hat = self.D_hat(d2[j])\n",
    "                err = self.error(d1_hat, d2_hat)\n",
    "                if err < er_best:\n",
    "                    er_best = err\n",
    "                    kp2u = u2[j]\n",
    "                    kp2v = v2[j]\n",
    "\n",
    "            for k in range(len(d2)):\n",
    "                if u2[k] != kp2u and v2[k] != kp2v:\n",
    "                    d2_hat2 = self.D_hat(d2[k])\n",
    "                    err2 = self.error(d1_hat, d2_hat2)\n",
    "                    if err2 < er_second:\n",
    "                        er_second = err2\n",
    "\n",
    "            if er_best < r * er_second:\n",
    "                if [u1[i], v1[i]] not in kp1:\n",
    "                    if [kp2u, kp2v] not in kp2:\n",
    "                        kp1.append([u1[i], v1[i]])\n",
    "                        kp2.append([kp2u, kp2v])\n",
    "\n",
    "        return np.asarray(kp1), np.asarray(kp2)\n",
    "\n",
    "    def find_homography(self, uv, uv2):\n",
    "        \"\"\"\n",
    "        Step 4: Find a linear transformation (of various complexities) that maps pixels from the second image to\n",
    "        pixels in the first image\n",
    "        \"\"\"\n",
    "\n",
    "        if uv.shape != uv2.shape:\n",
    "            raise ValueError(\"X and X_prime must have matching shapes\")\n",
    "        if uv.shape[0] < 4:\n",
    "            raise ValueError(\"Not enough points\")\n",
    "\n",
    "        # matches = np.column_stack(uv, uv2)\n",
    "\n",
    "        A = np.zeros((2 * len(uv), 9))\n",
    "\n",
    "        for i in range(len(uv)):\n",
    "            A[2 * i, :] = [0, 0, 0, -uv[i, 0], -uv[i, 1], -1, uv2[i, 1] * uv[i, 0], uv2[i, 1] * uv[i, 1], uv2[i, 1]]\n",
    "            A[2 * i + 1, :] = [uv[i, 0], uv[i, 1], 1, 0, 0, 0, -uv2[i, 0] * uv[i, 0], -uv2[i, 0] * uv[i, 1], -uv2[i, 0]]\n",
    "\n",
    "        # print(A)\n",
    "        U, Sigma, Vt = np.linalg.svd(A)\n",
    "\n",
    "        H = Vt[-1, :].reshape((3, 3))\n",
    "        H /= H[2, 2]\n",
    "\n",
    "        return H\n",
    "\n",
    "    def RANSAC(self, number_of_iterations=10, n=10, r=3, d=8):\n",
    "\n",
    "        H_best = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "        num_inliers = 0\n",
    "\n",
    "        k1, k2 = self.match_keypoints()\n",
    "        matches = np.column_stack((k1, k2))  # matches should be of the form [u1, v1, u2, v2]\n",
    "\n",
    "        for i in range(number_of_iterations):\n",
    "            # 1. Select a random sample of length n from the matches\n",
    "            np.random.shuffle(matches)\n",
    "            sub = matches[0:n, :]\n",
    "            test = matches[n:, :]\n",
    "\n",
    "            # 2. Compute a homography based on these points using the methods given above\n",
    "            H = self.find_homography(sub[:, 0:2], sub[:, 2:])\n",
    "\n",
    "            # 3. Apply this homography to the remaining points that were not randomly selected\n",
    "            test_p = test[:, 0:2]\n",
    "            test_p = np.column_stack((test_p, np.ones(len(test_p))))\n",
    "            uv_p = (H @ test_p.T).T\n",
    "            test_u = uv_p[:, 0] / uv_p[:, 2]\n",
    "            test_v = uv_p[:, 1] / uv_p[:, 2]\n",
    "\n",
    "            # 4. Compute the residual between observed and predicted feature locations\n",
    "            R = np.zeros_like(test_u)\n",
    "            for i in range(len(test_p)):\n",
    "                R[i] = np.sqrt((test_u[i] - test[i, 2]) ** 2 + (test_v[i] - test[i, 3]) ** 2)\n",
    "\n",
    "            # 5. Flag predictions that lie within a predefined distance r from observations as inliers\n",
    "            inl = np.zeros_like(R)\n",
    "            for i in range(len(inl)):\n",
    "                if R[i] < r:\n",
    "                    inl[i] = 1\n",
    "                else:\n",
    "                    inl[i] = 0\n",
    "            num_inl = np.sum(inl)\n",
    "\n",
    "            # 6. If number of inliers is greater than the previous best\n",
    "            #    and greater than a minimum number of inliers d,\n",
    "            #    7. update H_best\n",
    "            #    8. update list_of_inliers\n",
    "            if num_inl > num_inliers:\n",
    "                if num_inl > d:\n",
    "                    H_best = H\n",
    "                    num_inliers = num_inl\n",
    "\n",
    "        return H_best, num_inliers\n",
    "\n",
    "    def stitch(self):\n",
    "        \"\"\"\n",
    "        Step 5: Transform second image into local coordinate system of first image, and (perhaps) perform blending\n",
    "        to avoid obvious seams between images.\n",
    "        \"\"\"\n",
    "        H_best = self.RANSAC(10, 10, 3, 8)\n",
    "\n",
    "        im1 = self.images[0]\n",
    "        im2 = self.images[1]\n",
    "\n",
    "        transform = skt.ProjectiveTransform(H_best)\n",
    "        im_2_warped = skt.warp(im2, transform, output_shape=(im1.shape[0], im1.shape[1] + (int(im1.shape[1] * 0.4))))\n",
    "\n",
    "        im1t = np.zeros_like(im_2_warped)\n",
    "\n",
    "        for v in range(im1.shape[0]):\n",
    "            for u in range(im1.shape[1]):\n",
    "                if im1[v, u] != 0:\n",
    "                    im1t[v, u] = im1[v, u]\n",
    "\n",
    "        img_out = np.zeros_like(im_2_warped)\n",
    "\n",
    "        for v in range(img_out.shape[0]):\n",
    "            for u in range(img_out.shape[1]):\n",
    "                if im1t[v, u] == 0 and im_2_warped[v, u] == 0:\n",
    "                    img_out[v, u] = 0\n",
    "\n",
    "                elif im1t[v, u] != 0 and im_2_warped[v, u] == 0:\n",
    "                    img_out[v, u] = im1[v, u]\n",
    "                elif im1t[v, u] == 0. and im_2_warped[v, u] != 0:\n",
    "                    img_out[v, u] = im_2_warped[v, u]\n",
    "                else:\n",
    "                    img_out[v, u] = (im_2_warped[v, u] + im1[v, u]) / 2\n",
    "\n",
    "        return img_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will populate these functions over the next several weeks, a process that will involve delving into some of the most elementary operations in digital signal processing.  \n",
    "\n",
    "As a test case, apply your stitcher to at least four overlapping images that you've taken.  With a stitcher that works on two images, more images can be added by applying the method recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
